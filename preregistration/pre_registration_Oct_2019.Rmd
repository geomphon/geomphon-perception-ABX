---
title: "Pre-registration_Geomphon_hindi"
author: "Amelia"
date: "01/10/2019"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

# Letter 

The process of perception of an unfamiliar speech sound is theorized to involve a comparison of the unfamiliar sound to representations of familiar sounds heard in the past.  However, research testing the ability to discriminate an unfamiliar sound often focuses on the difference betweeen the unfamiliar sound and one familiar sound that is determined to be the "nearest" sound in perceptual or acoustic space.  This narrow focus on the one nearest sound ignores the rest of a large and often crowded represetation space.  

This is important because it is known that sound inventories of language are not random in their geometric shape, but instead can be measured to have global and local symmetry and economy, above and beyond what would be expected by chance. (Dunbar & Dupoux 2016)   We ask: does the shape of the entire sound inventory affect discirmination of an unfamiliar sound, above and beyond the effect of distance to the nearest sound? Our research has implications for theories of language change and second language acquisition and practical applications in language teaching. 


The study has been approved by  the Comité d’Éthique de la Recherche  of Université Paris Decartes as of June 13, 2019.  All funding for participant payment is covered by the Agence National de Récherche grant numbers ANR-17-CE28-0009 (GEOMPHON) and  ANR-10-LABX-0083 (EFL).   Web hosting for the online studies will be provided by the Laboratoire de Linguistique Formelle.  The study is ready to commence immediately.  

Data collection for the English speakers will take a maximum of one week to complete. Based on previous studies we expect recruitment of French participants will take longer, but we anticipate being able to run all participants within a two week window. Once data is collected all code is in place to immediately run models and create vizualizations.  At this point we will take one further week to move from a stage 1 manuscript to a stage 2 manuscript. The total time anticipated to go from in principle approval to stage 2 manuscript is one month.  

We agree to participate in the Open Peer Review system.  

Following Stage 1 in principle acceptance, we agree to register the approved protocol on the Open Science Framework either publicly or under private embargo until submission of the Stage 2 manuscript.  

If we should withdraw the paper following in principle acceptance, we agree to the publicaiton of a short summary of the pre-registered study as a Withdrawn Registration.  


appropriate reviewers with expertise in linguistics and Bayesian Methods include:  

Jeff Mielke  
Timo Roettger  
Bodo Winter  
Till Poppels  


# Introduction
### background and literature review
Over a lifetime of speech perception, humans fine-tune their sensitivity to phonetic differences that are contrastive in their native language.  When listeners hear a new phone, be it a phone from a new language or a variant they have not previously encountered, they are faced with the task of perceiving new sounds with a perceptual system that is tuned to their native language.   There is extensive research investigating precisely how this is accomplished. In formal models of language learning such as the Speech Learning Model (Flege) and the Perceptual Assimilation Model (Best,1995, Best & Tyler 2007), an important concept that has arisen from past work is the distance of the unfamiliar sound to the nearest familiar sound in the native inventory.  Unfamiliar sounds will be hard to discriminate from a familiar sound that is close, and easier to discriminate from a familiar sound that is farther away.

This "distance" is defined in different ways: principally, as either an objective acoustic distance measured on some element of an acoustic signal, or as a perceptual distance which can be measured through discrimination tasks. However, a narrow focus on the distance between one familiar sound and one unfamiliar sound ignores the crucial fact that phonetic space is crowded for most sound inventories. An unfamiliar sound which is "far" from one familar sound may be "near" to other sounds, and if a distribution or category develops and changes over time, a move "farther" from one sound is likely to be "nearer" to another sound. We can measure this effect by looking at how the shape of an inventory would change if a new sound were added.  

We argue that perception of a phone involves not just the process of comparing the new sound to the nearest old sound, but also as the process of adding new sounds into an already established inventory.  In particular, we are interested in how an inventory would change if the new sound is incorporated. It has been shown previously that sound inventories are not random in their distribution of sounds (Dunbar & Dupoux 2016). Dunpar & Doupoux (2016) develop three measurements which encompass these values:  

1) economy ("Econ"): if two inventories have the same number of sounds, those sounds tend, all things being equal, to require relatively few features to characterize  

2) local symmetry ("Loc") : if two inventories have the same number of sounds, using the same number of features, those sounds tend to make relatively many "minimal oppositions" between pairs of sounds, which differ only in one feature  

3) global symmetry ("Glob"): if two inventories are matched geometrically on the other two properties, they tend to have sounds that are more symmetrically distributed	

Because these metrics measure the geometry of an entire inventory,  we call these measures "geomphon scores" The calculation of these scores is based on discrete phonological features, and details of the precise method are available in Dunbar & Dupoux (2016).  While Dunbar & Dupoux establish that sound inventories of the worlds languages maximize these properties above and beyond the distribution expected by chance, they do not establish *why* inventories maximize these scores.  One possible reason is that inventories that maximize these scores are optimal for discrimination of sounds within an inventory.  This would lead to the prediction that a change in inventory that reduces one of these scores would lead to worse discrimination, when compared to a change in inventory that increases one of these scores. 

In this project, we collect discrimination data from an ABX task in which listeners discriminate pairs of sounds. We use French and English speakers, listening to unfamiliar Hindi sounds. 

### Experimental aims 
The experiment aims to test whether the spatial relation of all the sounds in a phoneme inventory affect perception of a given unafamiliar sound.  Specifically, we test whether changes in geomphon scores are predictive of discrimination accuracy, above and beyond the effect of acoustic distance to one nearest sound. 

### Hypotheses 
H1) We hypothesize that, as previous research has shown, a pair of sounds that are farther apart in acoustic distance will be easier to discriminate than two sounds that are very close in acoustic distance. 

H2) We hypothesize that changes in Econ, Glob, and Loc will each be predictive of discimination accuracy, above and beyond the effect of acoustic distance.   

# Method

### sample 
#### population 
 Participants will be recruited in three venues:  
 
1) English speaking participants will be recruited on Amazon Mechanical Turk, with qualifications set to:  
    * location is US  
    * approval rate 95% or higher  
    * have completed > 100 HITS  
    * following mechanical turk's policies, all Amazon Mechanical Turk participants are > 18 years of age  

2) French speaking paricipants will be recruited recruited on Amazon Mechanical Turk, with qualifications set to:   
    * location is France  
    * approval rate 95% or higher  
    * have completed > 100 HITS  
    * following mechanical turk's policies, all Amazon Mechanical Turk participants are > 18 years of age
    
3) French speaking participants will also be recruited through RISC and the facebook groups for linguistics and Psychology research.  
**DECISION: will we use these? will these speakers be paid?** 
    
  
#### Inclusion and exclusion criteria
Each participant will answer a demographic survey designed to determine their eligibility.  To incentivize truthful behavior in online participants, all Mechanical Turk participants will be paid regardless of their answers.

Data from any subject who meets **any** of the following criteria will be **excluded**.  

1) They answer "Yes" to question "Do you have any problems with your hearing or vision, other than glasses/contacts?"
2) They answer "Yes" to question "Have you been diagnosed with a speech or language impairment?"
3) They answer "Yes" to question "Have you ever taken a linguistics course?"
4) **DECISION: include this?? Their answer to the question "Do you have an idea about what we might have been investigating?" indicates that they were aware of the purporse of the experiment.**
5) They indicate they have high proficiency in another language  **(They answer ___ to the question ___)
6) they indicate they have high experience in another language  (They answer ___ to the question ___)  
7) they indicate they have both medium proficiency and medium experience in another language  
8) **DECISION: INCLUDE THIS?Their performance is not significantly different from chance, as determined by___**  
9) **DECISION: INCLUDE THIS? Their performance is not significantly different from ceiling, as determined by___**  
10) **DECISION: INCLUDE THIS? Participant has NA/no data for >2 trials (for any reason, e.g.user error, unanticipated technical error)**

We will run  a batch of 90 subjects (the total goal number, based on power analysis below), and then run the above analyses to determine the number of subjects that pass all criteria.  We will then run batches of size (90 - number who have already passed the above criteria) until we reach 90 subjects.  Each batch of data will be posted to OSF in raw, anonymized format on the day of collection, before a new batch is collected. 


#### number of subjects 


Our goal was to ensure that for our given design there would be enough data that the mean of the posterior distribution would not differ greatly from the true effect. To determine the number of subjects necessary to achive this goal, we tested directly by sampling datasets based on a variety of values of coefficients, and then running models to detect these known coefficient values.

We graph below the difference between the value input as the coefficient and the mean of the posterior for 27 combinations of values (All combinations of 3 coefficient values (-1,0,1),  for 3 predictors) .  In the best case scenario the mean of the posterior is exactly the same as the coefficient value we used to sample the data, and therefore the difference shown on this graph is zero. We can see that the distribution approaches zero as the number of subjects increases. 

An N of **90 subjects** was selected as the best balance between the practicalities of running many subjects and the extent to which the mean of the posterior distribution would reflect the true value. 

```{r power analysis, echo=FALSE, warning= FALSE, message = FALSE}
hindi_dinst1<-readr::read_csv("final_corr_master_hindi_dinst1.csv")
  hindi_dinst1$numsubjs<-30
hindi_dinst2<-readr::read_csv("final_corr_master_hindi_dinst2.csv")
  hindi_dinst2$numsubjs<-30
hindi_dinst3<-readr::read_csv("final_corr_master_hindi_dinst3.csv")
  hindi_dinst3$numsubjs<-60
hindi_dinst4<-readr::read_csv("final_corr_master_hindi_dinst4.csv")
  hindi_dinst4$numsubjs <- 90
hindi_dinst5<-readr::read_csv("final_corr_master_hindi_dinst5.csv")
  hindi_dinst5$numsubjs<- 10
  
hindi_for_hists<-dplyr::bind_rows(hindi_dinst1,
                                  hindi_dinst2,
                                  hindi_dinst3,
                                  hindi_dinst4,
                                  hindi_dinst5) 

ggplot2::ggplot(hindi_for_hists, ggplot2::aes(x = Econ_glm_diff)) +
    ggplot2::geom_histogram(binwidth = .1,
                            position="identity",
                            alpha = 0.4)+
    ggplot2::scale_x_continuous(limits = c(-10,10))+
    ggplot2::ggtitle("Econ coef differenece,hindi data,
                                        calculated by glm, by number of subjects")+
    ggplot2::facet_grid(numsubjs ~ .)


ggplot2::ggplot(hindi_for_hists, ggplot2::aes(x = Glob_glm_diff)) +
    ggplot2::geom_histogram(binwidth = .1,
                            position="identity",
                            alpha = 0.4)+
    ggplot2::scale_x_continuous(limits = c(-10,10))+
    ggplot2::ggtitle("Glob coef differenece, hindi data,
                     calculated by glm, by number of subjects")+
    ggplot2::facet_grid(numsubjs ~ .)


ggplot2::ggplot(hindi_for_hists, ggplot2::aes(x = Loc_glm_diff)) +
    ggplot2::geom_histogram(binwidth = .1,
                            position="identity",
                            alpha = 0.4)+
    ggplot2::scale_x_continuous(limits = c(-10,10))+
    ggplot2::ggtitle("Loc coef differenece, hindi data,
                                 calculated by glm, by number of subjects")+
    ggplot2::facet_grid(numsubjs ~ .)


```

### stimuli 

##### Choice of unfamiliar language:  
 For practical reasons our discrimination experiments are to be run with English and French listeners, and therefore it was necessary to find a language which has some sounds that are similar to sounds in the inventory of French and English, and some sounds that are highly dissimilar. In addition, the unfamilar sounds should involve the best spread of each geomphon score, as well as acoustic distances. 

While geomphon scores can be calculated based on a full inventory of consonants and vowels,  practically speaking, discrimination between pairs of sounds consisting of one vowel and one consonant would yield ceiling level accuracy and be uninformative for our research question. We therefore chose to use only consonants. 

Dunbar and Dupoux calculated Geomphon scores for **N** languages and the feature matrices used to do this are available **here**  Using these matrices, we identified a list of languages that  **criteria**. We then calculated scores base don **fill in details from monday meeting**

Of the languages on this list, Hindi was chosen because it was a language that has many consonants that are familiar to French and English speakers (e.g. /n/,/m/, /b/, /j/), and also many that are unfamiliar (in particular, retroflex sounds,  and voiced aspirated stops).  It was also a language for which we would be able to recruit model speakers in France and the United States. 
 
##### Procedure for recording of stimuli: 
 
5 Hind-Urdu speakers (3 female) were recorded in a sound attenuated booth in either the Université de Paris or the University of Massachusetts.   All reported that Hindi was the principal language they spoke with their family as children.  The primary motivation for using multiple speakers was to introduce variability and noise into the experiment, and so the speakers were not controlled for sociolinguistic factors (e.g. age, place of birth,etc.) Each speaker was paid  $20/€20 for their recording and signed an informed consent form.  
 
 Participants spoke all consonants of Hindi in a pseudoword /a_a/ context.  Each pseudo word was written on a list in Devanagri and latin script, with a sample word in Devanagri including the target consonant sound.  For elicitation purposes each pseudoword was said in a sentence context "kripya ____ kahie" (कृपया_____कहिए") ("please bring _____"). Speaker 1 recorded all peseudowords once.  Speakers 2-5 recorded all pseudowords twice.  The  first time, speakers 2-5 listened to speaker 1, and then paused the recording and repeated after Speaker 1.  They were told to try to repeat at about the same pace.  Recordings are considered individually identifiable information and so are not available publically, but are approved for sharing for research purposes, including replication. To obtain access to the files email ewan.dunbar@univ-paris-diderot.fr.  

Textgrids for all recordings were created using forced alignment using **the Penn forced aligner**. Transcripts, code, and textgrids are available at **URL**.  All textgrids were hand checked and ajusted for accuracy through visuali in Praat, and all splice points were moved to the nearest zero crossing.  
 
 
#### procedure for building and selecting stimuli 
 
Each stimulus tests one pair of phonemes.  One member of the pair is a familiar sound, and one member is an unfamiliar sound.   The "familiar" sounds were phonesthat are included in both French and English inventories (i.e. would be transcribed as the same IPA symbol in French, English, and Hindi).  The familiar sounds are listed below: 
/b,d,g,p,t,k,v,ð,z,s,d͡ʒ,t͡ʃ,n,j,ɾ,h,ʃ/

The unfamiliar sounds, on the other hand, were sounds which are  present in the inventory of Hindi byt unambiguously absent in both French and English.  The unfamiliar sounds are listed below:

/bʰ,d̪ʰ,ɖ,ɖʰ,dʒʰ,ɡʰ,ɳ,ɽ,ʈ/

Each unfamiliar sound was paired with the familiar sounds which we judged to be most similar. Examples of the pairs formed for the unfamiliar sounds /bʰ/, /ʈ/, and /ɳ	/ are below:  

bʰ	b
bʰ	d
bʰ	g
bʰ	p
bʰ	t
bʰ	k
bʰ	v
ʈ	t
ʈ	d
ɳ	n
ɳ	j

It is important to clarify that both the familiar and unfamiliar sounds were spoken by the Hindi speakers. We acknowledge that because they were spoken by Hindi speakers, the "familiar" sounds may differ systematically from the English and French version of these sounds. The rationale for performing the experiment this way was to have consistency in the context surrounding the phone of interest.  If instead English speakers recorded the English consonants and Hindi speakers the Hindi consonants, the surrounding vowels have the potential to give additional cues useful for discrimination and push discrimination towards ceiling, **as  we found in previous pilot X**. While the "familiar" sounds may differ slightly from their versions in English and French, the unfamiliar sounds were chosen to be much further than unfamiliar sounds in acoustic distance and phonological features.   (**and indeed our measurements confirm this**). 

## Selection of stimuli
Selection of triplet stimuli is based on four things: 

1) acoustic distances 
     a) distance to target <  distance to other 
     b) ratio of differences is not so large as to create only ceiling performance
         --> currently: log ratio is > -.4)
     
2) GEOMPHON scores 
    c) prefer triplest Econ, Glob, Loc as uncorrelated as possible in order to improve model performance 
    
3) Domain knowledge 
    d) rule out stimuli that do not sound good to phoneticians 
         -->remove velar fricatives, which were not native to our speaker's dialects
    e) attempt to balance stimuli by linguistic categories 
         --> sample one instance from each phone pair before further sampling to arrive at 150 stimuli
         
4)expeirmental balance
   f) once all above filters have been applied to select pairs, list of triplets is submitted to 
   simulated annealar script which will optimize a stimuli list that  has the best combinations 
   that decorrelate speaker combination from phone pair.

Once the pairs of phonemes were chosen, it was necessary to combine recordings of the sounds to create ABX trials. An ABX trial consists of a sound (A), a different sound (B), and then a repetition of either A or B (the X, which participants match to either A or B).  For a trial with a given pair of phonemes, it is necessary to determine the order of the phonemes, which sound is the target, and which speaker's recording is used.  The number of trials was constrained to 150 based on time estimates of previous experiments.  Given the number of permutations of these options it is not feasible to simply counterbalance all combinations of order, target phone, and speaker within the number of trials. 


## construction of stimuli 
Once the design is decided, each recording is spliced togehter with **______ ISI bewteen A&B and B& X**


### calculation of geomphon scores 


### experimental procedure

Code sufficient to launch a direct replication, including all demographic surveys, instructions, and stimuli, presented in a docker enviroment that replicates exactly the software versions, libraries, and modules we used,  can be found here:

___PERSISTENT URL. 

A description of method is below: 

Participants first read a consent form and indicate their consent. Then participants fill out a demographic survey. 

Participants hear a triplet

randomization, training, instructions, etc. 


### model specifications 

####  covariates 
the covariates in the model are acoustic distance, and the three geomphon scores 
**amelia incorporate pre-prereg_rmd**

acoustic distance -- how chose how calculated 
MFCCs? 
How to operationalize Acoustic distance log distance? delta distance? 
 
 
geomphon scores 


#### method to determine whether an effect of a coefficient is non-zero 
Based on our design we expect acoustic distance will be non-zero. (indeed, we have specifically designed the stimuli to ensure this is the case)
 
The effect of the geomphon scores, however, is as yet undetermined, and may be larger or smaller than the effect of acoustic distance. Therefore, a significant concern was to determine a model that would detect a difference between a small, positive effect and a zero effect. 

To this end, we use comparison of leave-one-out-cross valitation ("loo") scores with models specified with varying priors.  The loo value obtained is a measure of the predictive ability of a model.  Specifically, it is an estimate of out-of-sample predictive accuracy using within-sample fits. We use the pareto smoothed importance sampling implemented in the loo() package, as documented in Vehtari et al. (2016). 

Because we cannot be sure of the size of the expected effect, it is important to establish a methodology that is sensitive to small but non-zero positive effects.  To accomplish this we use loo() and truncated priors.  A truncated prior is simply a prior for which the density curve is truncated at some value. 

In our case, we use a normal(0,10) prior and truncate the value at zero. We can therefore apply a model truncated to be <= 0 to a model to be >= 0.   If an effect of interest is not meaningfully different than zero, two models, one with a truncated positive prior and one with a truncated negative prior will not differ (nor would they differ from a model with no effect of this predictor).  If, on the other hand, the effect is different from zero, either the truncated positive prior or the truncated negative prior will show better predictivity in the direction of the effect. 


For example, to test for an effect of Econ, we will run a model such as the following:

 accuracy ~ Econ + Glob + Loc + acoustic_distance + (1|Subject) + (1|phone_pair)

we will run the model three times:  

* Model A: removing the effect of Econ, (simulating a zero effect)  
  accuracy ~ Glob + Loc + acoustic_distance + (1|Subject) + (1|phone_pair),  
priors: N(0,10) for all covariates

* Model B applying a prior truncated to be >=0  
  accuracy ~ Econ + Glob + Loc + acoustic_distance + (1|Subject) + (1|phone_pair),  
prior Econ: truncated gaussian N(0,10) >=0
all other priors: N(0,10)

* Model C applying a prior trunacted to be <=0
accuracy ~ Econ + Glob + Loc + acoustic_distance + (1|Subject) + (1|phone_pair)
prior Econ: truncated gaussian N(0,10) <=0
all other priors: N(0,10)

We will then complete pairwise differences to compare the differences in loo scores between each of these four using loo_compare(), which gives a we used  the difference in  expected log predictive density (elpd_diff). The elpd_diff shows which model has a better loo score,  and therefore better predictive accuracy. The output of loo.compare() includes the s.e. of this difference score. We will determine whether two  models is meaningfully "different" by using the rule of thumb put forth by Vehtari that the elpd_diff is 5 times larger than it's s.e.*?*

In order to make all comparisons of all combinations of the three predictors of interest, we will run a total of 27 models (all combinations of 3 predictors (Econ, Glob, Loc) and three priors (truncated posistive, truncated negative, zero)).  

We will then use compare_models() in the loo package to obtain a ranking of their elpd_diff scores. 

We will interpret there to be a positive effect of one of the geomphon scores Model B is better than model A AND model C. 

#### random effects structure 



# Results & Analysis 

### Preprocessing 
Data will be filtered for whether it confirms to criteria outlined in subejct inclusion/exclusion above.    All data that meets criteria will be used in analysis. 

### reality checks 
Our hypotheses take for granted an effect of acoustic distance.  Therefore, an effect of acoustic distance is a required first step before interpreting the geomphon scores.(see interpretive plan, below)

# Interperative plan 


 Our interpretive plan therefore will be 

step 1: confirm effect of acoustic distance.

possible outcomes:

a) there is no effect of acoustic distance, as determined by ________
  
We will interpret this as a failure to replicate the well-known effect of acoustic distance. Given that the stimuli were chosen specifically to have an effect of acoustic distance, that the number of subjects was chosen specifically to be able to robustly detect this effect, and that three previous pilots show large significant effects of distance, we will we will consider this a fatal failure of the experimental protocol.  We will withdraw the study and pre-register a new experimental protocol with more subjects and/ or an easier task in order to detect the effect of acoustic distance. 

b) there is an effect of acoustic distance 

We will interpret this to be a confirmation that our experimental protocol was well-designed to detect the effects of interest. 


step 2:  examine the effect of geomphon scores

possible outcomes: 

a) there is an effect of one or more of the geomphon features, above an beyond the effect of acoustic distance only. 

b) there is no effect of any of the geomphon scores above and beyond the effect of acoustic distance. 



# timeline 
 Timeline for completion of the study and proposed resubmission date if registration review is successful. Extensions to this deadline can be negotiated with the action editor.




