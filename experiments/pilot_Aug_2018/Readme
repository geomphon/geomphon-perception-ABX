
This folder contains the files for the Aug 2018 Pilot 

This differs from the July pilot in two ways. 
    1 new stimuli 
      -stimuli recorded in sound booth by native English speakers 
      -both vowels and consonants 
    2 new presurvey-  improved language in demographic questionnaire 


TO CREATE STIMULI:

1. Stimuli folder containing
	-full recordings of stimuli (ewan.wav,amelia_consonants.wav,amelia_vowels.wav)
	-their accompanying textgrids  (amelia_consonants_ONLY_TARGET_CHECKED.TextGrid etc)
		-these textgrids have a tier (2) with only the target word (no recording context)
		-these textgrids have been handcheecked for accuracy after running forced aligner

2. save_intervals_to_wavs.Praat :script for cutting out just target words and saving them as separate .wavs. NB the output directory specified here must exist already, the script will fail rather than create one if you specify a directory that does not exist.  NB that this script is written for the specific files for this experiment, and must be edited for use with different sound files. 

3. scale_intensity.Praat: script for normalising intensity of all files in a directory. 

4. generate triplet list  triplets.csv:  a list of all possible triplets 
FIXME-add

5. create_stimlist.py : a script that takes triplets.csv and filters it to create an optimised stimuli list,

6. reformat_stimlist.R takes created stimuli list from create_stimlist.py and reformats to match optimised list to strings that are filenames.  This new reformatted stimuli list is saved as as a .txt file to read in to Praat (Praat script will take only txt file) 

7. concatenation_of_tripets.Praat : takes the stimlist created by reformat_stimlist.R and the .wavs created by save_intervals_to_wavs.Praat (which have been normalised by Normalize_intensity.Praat), and creates triplet files. Note that all files must be the same sampling frequency, even silences

8. Bash script geomphon_Aug_2018.sh which runs all the above 6 steps in the above order. 



TO CREATE NEW EXPERIMENT: 

1. UPDATE BY HAND
		-update LMEDs dictionary (with new experiment finish code for turkers, if nothing else)
		-(if necessary update sequence file to reflect new stimuli)
		-(if necessary update surveysâ€” If update, then update cleaning script by hand)
		-update .cgi file 
		-update output folder to have name that is the same as the sequence file name

2. Push updates to server 

3. Update server permissions to allow experiment to run
   -cgi must be executable 
   -output folders must have write permissions. 


TO CLEAN DATA: 

1. Anonymize data 
 Run anonymize_lmeds_data_filenames.py  

FIRST ARGUMENT: the folder containing the raw LMEDS data, ending in ".csv"
SECOND ARGUMENT: the folder to output to; the internal structure of the input folder will be
preserved; this folder will be created if it doesn't already exist, but it will *not* 
be cleaned out if it already exists, so be careful
THIRD ARGUMENT: The anonymization CSV to be created. This maps the real ids to anonymised one
This CSV should be stored as individually identifiable information and never changed. 



2. Run clean_output_pilot_Aug_2018.py  
this script takes as input a directory of raw LMEDS data files  
*WITH nested subdirectories* for English and French data. 

takes the following arguments: 
folderpath = sys.argv[1]
results_filename = sys.argv[2]
presurvey_filename = sys.argv[3]
postsurvey_filename = sys.argv[4]
postsurvey2_filename = sys.argv[5]



3. Run analysis_step1_preprocess_Aug_2018_pilot.R

This takes the results, combines with subject and item info, 

It yields a .csv that is ready for analysis 




TO ANALYZE DATA
1. Calculate Acoustic scores 
2. Calculate Geomphon scores 
3. Analyse in R project. 






