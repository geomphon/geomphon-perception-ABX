---
title: "Summary of Aug 2018 pilot results with distances"
author: "Amelia"
date: "10/18/2018"
output: html_document
---

## R Markdown
```{r accuracy,echo=FALSE}
rm(list=ls())
library(magrittr)
library(dplyr)
library(ggplot2)
library(tidyr)


results<-read.csv("/Users/post-doc/Desktop/geomphon_pilot_results_for_analysis.csv")


by_cons<-group_by(results,phone_OTH,phone_TGT,CV_X,subject_language)%>%
  summarise(accuracy = mean(user_corr))

wide_by_cons<-spread(by_cons,key=subject_language,value=accuracy)

wide_by_cons<-mutate(wide_by_cons,char_phone=paste(phone_OTH,phone_TGT,sep = "-" ))


plot(wide_by_cons$English,wide_by_cons$French, col ="white" )
text(wide_by_cons$English,wide_by_cons$French,labels = wide_by_cons$char_phone)






#group by tripletid, which is the stimulus, then summarise how many correct answers for that triplet
grouped<- dplyr::group_by(results,tripletid,log_delta_dist_div,delta_dist_div,delta_dist_sub) %>%
  summarise(num_corr = sum(user_corr))

#add accuracy by dividing by the number of subjects that passed filtering.
#17 = total number of subjects left after filtering
grouped$accuracy<-grouped$num_corr/17


#files 49,50,100 and 104 were used as practice, so they have double the number of trials, so accuracy is calculated differently. 
#NB this is a fragile and dumb way to do this!  this will mess up if the df changes    #FIXME
grouped[3, 6] = 19/34 #simulus 100
grouped[7, 6] = 24/34 #stimulus 104
grouped[89, 6] = 19/34 #stimulus 49 
grouped[91, 6] = 21/34 #stimulus 50










```
Overall accuracy, English and French pooled


```{r graph, echo=FALSE}
hist(grouped$accuracy)
plot(grouped$tripletid, grouped$accuracy, ylab="Proportion Correct")

plot(grouped$log_delta_dist_div, grouped$accuracy, xlab = "log(Target distance/Other distance)")
abline(fit<-lm(grouped$accuracy~grouped$log_delta_dist_div), col = "red")
legend("topright", bty="n", legend=paste("R2 =", format(summary(fit)$adj.r.squared, digits=4)))

plot(grouped$delta_dist_div, grouped$accuracy,xlab ="Target distance/Other distance")
abline(fit<-lm(grouped$accuracy~grouped$delta_dist_div), col = "red")
legend("topright", bty="n", legend=paste("R2 =", format(summary(fit)$adj.r.squared, digits=4)))

plot(grouped$delta_dist_sub, grouped$accuracy, xlab ="Target distance - Other distance")
abline(fit<-lm(grouped$accuracy~grouped$delta_dist_sub), col = "red")
legend("topright", bty="n", legend=paste("R2 =", format(summary(fit)$adj.r.squared, digits=4))

```


Accuracy by language group

```{r accuracy_by_lang}
lang_Eng<-filter(results,subject_language.y=="English")
lang_French<-filter(results,subject_language.y=="French")

English_acc<-group_by(lang_Eng,tripletid) %>%
      summarise(num_corr = sum(user_corr))

#8 English subjects left after filtering
English_acc$accuracy<-English_acc$num_corr/8
  
English_acc[3, 3] = 7/16 #simulus 100
English_acc[7, 3] = 12/16 #stimulus 104
English_acc[89, 3] = 9/16 #stimulus 49 
English_acc[91, 3] = 9/16 #stimulus 50


French_acc<-group_by(lang_French,tripletid) %>%
        summarise(num_corr = sum(user_corr))

#9 French subjects left after filtering
French_acc$accuracy<-French_acc$num_corr/10  

#FIXME PROBLEM
French_acc[56, 3] = 10/10 #simulus 100

French_acc[3, 3] = 12/18 #simulus 100
French_acc[7, 3] = 12/16 #stimulus 104
French_acc[89, 3] = 10/16 #stimulus 49 
French_acc[91, 3] = 12/16 #stimulus 50

plot(English_acc$accuracy,French_acc$accuracy)
abline(fit<-lm(French_acc$accuracy ~English_acc$accuracy), col = "red")
```


```{r language graphs}
hist(English_acc$accuracy, xlab="Proportion Correct", main="Accuracy by stimulus for English participants")
plot(English_acc$tripletid, English_acc$accuracy,ylab="Proportion Correct")

#vizualize consonants and vowels


hist(French_acc$accuracy,xlab="Proportion Correct",main="Accuracy by stimulus for French participants")
plot(French_acc$tripletid, French_acc$accuracy,ylab="Proportion Correct")
```
